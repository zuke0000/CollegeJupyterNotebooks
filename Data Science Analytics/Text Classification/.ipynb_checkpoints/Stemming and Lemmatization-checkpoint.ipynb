{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d364c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "098a6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc989296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\derrick\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\derrick\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\derrick\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\derrick\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: joblib in c:\\users\\derrick\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\derrick\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "# install the nltk (natural language toolkit) library\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc96e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "# sentences\n",
    "X_train = ['I love the book', \n",
    "           'This is a great book',\n",
    "          'The fit is great',\n",
    "          'I love the shoes']\n",
    "# topics of sentences\n",
    "y_train = ['books', 'books', 'clothings', 'clothings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a2d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de11778c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>fit</th>\n",
       "      <th>great</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>shoes</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book  fit  great  is  love  shoes  the  this\n",
       "0     1    0      0   0     1      0    1     0\n",
       "1     1    0      1   1     0      0    0     1\n",
       "2     0    1      1   1     0      0    1     0\n",
       "3     0    0      0   0     1      1    1     0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)\n",
    "# document term matrix. Matrix with the counts\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "pd.DataFrame(X_train_dtm.toarray(), \n",
    "             columns=vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5613568",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = ['I like the book', \n",
    "          'Shoes are alright', \n",
    "          'I love the books',\n",
    "         'I lost a shoe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f1ee203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X=X_train_dtm, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bd357b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['books', 'clothings', 'clothings', 'books'], dtype='<U9')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm = vect.transform(X_test)\n",
    "nb_clf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f0f4f8",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40043513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Derrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Derrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Derrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Derrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Derrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6adcff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93d1c6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book\n",
      "read\n"
     ]
    }
   ],
   "source": [
    "# initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem('books'))\n",
    "print(stemmer.stem('reading'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c40f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'I love the books'\n",
    "words = word_tokenize(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d69213b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'the', 'book']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words = [stemmer.stem(word) for word in words] # some nice python syntax\n",
    "stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63fa758f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love the book'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f9fbf",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92cc4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abae3937",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cff25b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# needs parts of speech\n",
    "lemmatizer.lemmatize('eats', pos='v') # v for verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b78b062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'the', 'books']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2387daf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('love', 'VBP'), ('the', 'DT'), ('books', 'NNS')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(words) # tells if a word is a verb (VBP) or a noun (NNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1f7575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parts of speech processing function\n",
    "def process_pos(pos):\n",
    "    if pos.startswith('J'): # adjective\n",
    "        return wordnet.ADJ\n",
    "    elif pos.startswith('V'): # verb\n",
    "        return wordnet.VERB\n",
    "    elif pos.startswith('N'): # noun\n",
    "        return wordnet.NOUN\n",
    "    elif pos.startswith('R'): #adverb\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eaeecf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('love', 'VBP'), ('the', 'DT'), ('books', 'NNS')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7dc452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_words = [lemmatizer.lemmatize(word, pos=process_pos(pos))\n",
    "                   for word,pos in nltk.pos_tag(words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "44d2a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'example of sentence removal of stopwords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "879ee4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello ! ?'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words\n",
    "\n",
    "words = word_tokenize(phrase)\n",
    "stripped_phrase = [word for word in words if word not in stop_words]\n",
    "' '.join(stripped_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fffdc7",
   "metadata": {},
   "source": [
    "## Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c93e647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import string\n",
    "punctuation = [punc for punc in string.punctuation]\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "942a39ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello ! ?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = \"Hello! how are you?\"\n",
    "words = word_tokenize(phrase)\n",
    "stripped_phrease = [word for word in words if word not in punctuation]\n",
    "' '.join(stripped_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7fc9f8",
   "metadata": {},
   "source": [
    "## Yelp reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "630a326f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  My wife took me here on my birthday for breakf...      5\n",
       "1  I have no idea why some people give bad review...      5\n",
       "2  love the gyro plate. Rice is so good and I als...      4\n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      5\n",
       "4  General Manager Scott Petello is a good egg!!!...      5"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/um-perez-alvaro/Data-Science-Practice/master/Data/yelp.csv'\n",
    "yelp = pd.read_csv(url)[['text','stars']]\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "18b03635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    3526\n",
       "5    3337\n",
       "3    1461\n",
       "2     927\n",
       "1     749\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bd892ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>Yes I do rock the hipster joints.  I dig this ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>Only 4 stars? \\n\\n(A few notes: The folks that...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>I'm not normally one to jump at reviewing a ch...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>Let's see...what is there NOT to like about Su...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  stars\n",
       "9990  Yes I do rock the hipster joints.  I dig this ...      5\n",
       "9991  Only 4 stars? \\n\\n(A few notes: The folks that...      5\n",
       "9992  I'm not normally one to jump at reviewing a ch...      5\n",
       "9994  Let's see...what is there NOT to like about Su...      5\n",
       "9999  4-5 locations.. all 4.5 star average.. I think...      5"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to 5- and 1- star reviews\n",
    "yelp = yelp.loc[yelp.stars.isin([1,5])]\n",
    "yelp.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b131cb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\\n\\nDo yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I\\'ve ever had.  I\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\\n\\nWhile EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I\\'ve ever had.\\n\\nAnyway, I can\\'t wait to go back!'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = yelp.loc[yelp.stars==5].iloc[0].text\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a0c85ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"wife take birthday breakfast excellent weather perfect make sit outside overlook ground absolute pleasure waitress excellent food arrive quickly semi-busy saturday morning look like place fill pretty quickly early get good favor get bloody mary phenomenal simply best 've ever 'm pretty sure use ingredient garden blend fresh order amaze everything menu look excellent white truffle scramble egg vegetable skillet tasty delicious come 2 piece griddle bread amaze absolutely make meal complete best `` toast '' 've ever anyway ca n't wait go back\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process the text\n",
    "text = yelp.loc[0,'text']\n",
    "words = word_tokenize(text)\n",
    "words = [word.lower() for word in words]\n",
    "lemmatized_words = [lemmatizer.lemmatize(word,pos=process_pos(pos))\n",
    "                   for word,pos in nltk.pos_tag(words)\n",
    "                   if word not in stop_words and word not in punctuation\n",
    "                   ]\n",
    "' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f466b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp['processed_text'] = yelp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8eae1647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words]\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word,pos=process_pos(pos))\n",
    "                       for word,pos in nltk.pos_tag(words)\n",
    "                       if word not in stop_words and word not in punctuation\n",
    "                       ]\n",
    "    return(' '.join(lemmatized_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dbdf299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"wife take birthday breakfast excellent weather perfect make sit outside overlook ground absolute pleasure waitress excellent food arrive quickly semi-busy saturday morning look like place fill pretty quickly early get good favor get bloody mary phenomenal simply best 've ever 'm pretty sure use ingredient garden blend fresh order amaze everything menu look excellent white truffle scramble egg vegetable skillet tasty delicious come 2 piece griddle bread amaze absolutely make meal complete best `` toast '' 've ever anyway ca n't wait go back\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ee54c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp['processed_text'] = yelp.text.apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b4e85a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>5</td>\n",
       "      <td>wife take birthday breakfast excellent weather...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>5</td>\n",
       "      <td>idea people give bad review place go show plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>5</td>\n",
       "      <td>rosie dakota love chaparral dog park 's conven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>5</td>\n",
       "      <td>general manager scott petello good egg go deta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Drop what you're doing and drive here. After I...</td>\n",
       "      <td>5</td>\n",
       "      <td>drop 're drive eat go back next day food good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>Yes I do rock the hipster joints.  I dig this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>yes rock hipster joint dig place little bit sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>Only 4 stars? \\n\\n(A few notes: The folks that...</td>\n",
       "      <td>5</td>\n",
       "      <td>4 star note folk rat place low must isolate in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>I'm not normally one to jump at reviewing a ch...</td>\n",
       "      <td>5</td>\n",
       "      <td>'m normally one jump review chain restaurant e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>Let's see...what is there NOT to like about Su...</td>\n",
       "      <td>5</td>\n",
       "      <td>let 's see ... like surprise stadium well 9.50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>5</td>\n",
       "      <td>4-5 location .. 4.5 star average .. think ariz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4086 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  stars  \\\n",
       "0     My wife took me here on my birthday for breakf...      5   \n",
       "1     I have no idea why some people give bad review...      5   \n",
       "3     Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      5   \n",
       "4     General Manager Scott Petello is a good egg!!!...      5   \n",
       "6     Drop what you're doing and drive here. After I...      5   \n",
       "...                                                 ...    ...   \n",
       "9990  Yes I do rock the hipster joints.  I dig this ...      5   \n",
       "9991  Only 4 stars? \\n\\n(A few notes: The folks that...      5   \n",
       "9992  I'm not normally one to jump at reviewing a ch...      5   \n",
       "9994  Let's see...what is there NOT to like about Su...      5   \n",
       "9999  4-5 locations.. all 4.5 star average.. I think...      5   \n",
       "\n",
       "                                         processed_text  \n",
       "0     wife take birthday breakfast excellent weather...  \n",
       "1     idea people give bad review place go show plea...  \n",
       "3     rosie dakota love chaparral dog park 's conven...  \n",
       "4     general manager scott petello good egg go deta...  \n",
       "6     drop 're drive eat go back next day food good ...  \n",
       "...                                                 ...  \n",
       "9990  yes rock hipster joint dig place little bit sc...  \n",
       "9991  4 star note folk rat place low must isolate in...  \n",
       "9992  'm normally one jump review chain restaurant e...  \n",
       "9994  let 's see ... like surprise stadium well 9.50...  \n",
       "9999  4-5 location .. 4.5 star average .. think ariz...  \n",
       "\n",
       "[4086 rows x 3 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "040d25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB # or any other classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c983720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yelp.processed_text\n",
    "y = yelp.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d5519e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f948d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(max_features = 1000, ngram_range=(1,2))), # idk what ngram range is. less features better for TfidVectorizer\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "72b6649f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 2))),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fb561058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 61, 138],\n",
       "       [  1, 822]], dtype=int64)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = pipe.predict(X_test)\n",
    "confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29788c",
   "metadata": {},
   "source": [
    "## Grid search on TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "81cae2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dic = {'vectorizer__max_features':[500,1000,2000,4000],\n",
    "             'vectorizer__ngram_range': [(1,1), (1,2)],\n",
    "             'vectorizer__use_idf': [False, True], # False (CountVectorizer), True (TfidfVectorizer)\n",
    "              'clf__alpha': [0.1,0.25,0.5,0.75],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c5b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(pipe, params_dic, cv=5, n_jobs=-1, scoring='roc_auc', verbose=2)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19019c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1098eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e9e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c832b6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4861eab7",
   "metadata": {},
   "source": [
    "## How does the Naive Bayes model choose 5 stars and 1 star?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "84103d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '07',\n",
       " '10',\n",
       " '10 15',\n",
       " '10 min',\n",
       " '10 minute',\n",
       " '10 year',\n",
       " '100',\n",
       " '101',\n",
       " '11',\n",
       " '11am',\n",
       " '12',\n",
       " '120',\n",
       " '13',\n",
       " '14',\n",
       " '140',\n",
       " '15',\n",
       " '15 20',\n",
       " '15 minute',\n",
       " '15 year',\n",
       " '150',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '1st',\n",
       " '20',\n",
       " '20 minute',\n",
       " '20 year',\n",
       " '200',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '21',\n",
       " '22',\n",
       " '24',\n",
       " '25',\n",
       " '2am',\n",
       " '2nd',\n",
       " '30',\n",
       " '30 min',\n",
       " '30 minute',\n",
       " '30 year',\n",
       " '30pm',\n",
       " '32',\n",
       " '35',\n",
       " '3rd',\n",
       " '40',\n",
       " '40 minute',\n",
       " '45',\n",
       " '45 minute',\n",
       " '49',\n",
       " '4pm',\n",
       " '50',\n",
       " '500',\n",
       " '5th',\n",
       " '60',\n",
       " '65',\n",
       " '6pm',\n",
       " '70',\n",
       " '75',\n",
       " '7th',\n",
       " '80',\n",
       " '90',\n",
       " '90 minute',\n",
       " '95',\n",
       " '99',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'able get',\n",
       " 'able make',\n",
       " 'absolute',\n",
       " 'absolute favorite',\n",
       " 'absolutely',\n",
       " 'absolutely amazing',\n",
       " 'absolutely delicious',\n",
       " 'absolutely love',\n",
       " 'ac',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'accessory',\n",
       " 'accommodate',\n",
       " 'accomodating',\n",
       " 'accompany',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'acknowledge',\n",
       " 'across',\n",
       " 'across street',\n",
       " 'act',\n",
       " 'action',\n",
       " 'active',\n",
       " 'activity',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actually get',\n",
       " 'actually go',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'added',\n",
       " 'added bonus',\n",
       " 'addict',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'adjacent',\n",
       " 'admit',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'advertise',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afraid',\n",
       " 'afternoon',\n",
       " 'afterwards',\n",
       " 'age',\n",
       " 'agent',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'ahead',\n",
       " 'ahi',\n",
       " 'ahwatukee',\n",
       " 'aid',\n",
       " 'air',\n",
       " 'airline',\n",
       " 'airport',\n",
       " 'airy',\n",
       " 'aisle',\n",
       " 'aj',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alcohol',\n",
       " 'ale',\n",
       " 'alfredo',\n",
       " 'all',\n",
       " 'allergic',\n",
       " 'allergy',\n",
       " 'allow',\n",
       " 'almond',\n",
       " 'almost',\n",
       " 'almost always',\n",
       " 'almost every',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'also come',\n",
       " 'also enjoy',\n",
       " 'also get',\n",
       " 'also give',\n",
       " 'also good',\n",
       " 'also great',\n",
       " 'also like',\n",
       " 'also love',\n",
       " 'also offer',\n",
       " 'also order',\n",
       " 'also really',\n",
       " 'also serve',\n",
       " 'also try',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'always',\n",
       " 'always busy',\n",
       " 'always clean',\n",
       " 'always come',\n",
       " 'always find',\n",
       " 'always fresh',\n",
       " 'always friendly',\n",
       " 'always get',\n",
       " 'always go',\n",
       " 'always good',\n",
       " 'always great',\n",
       " 'always leave',\n",
       " 'always look',\n",
       " 'always love',\n",
       " 'always make',\n",
       " 'always nice',\n",
       " 'always really',\n",
       " 'always take',\n",
       " 'ama',\n",
       " 'ama ebi',\n",
       " 'amanda',\n",
       " 'amaze',\n",
       " 'amaze food',\n",
       " 'amazing',\n",
       " 'amazing food',\n",
       " 'amazing place',\n",
       " 'amazing service',\n",
       " 'amazingly',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'amc',\n",
       " 'amenity',\n",
       " 'america',\n",
       " 'american',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'ample',\n",
       " 'amuse',\n",
       " 'and',\n",
       " 'and or',\n",
       " 'andrew',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'anniversary',\n",
       " 'annoy',\n",
       " 'another',\n",
       " 'another 20',\n",
       " 'another hour',\n",
       " 'another one',\n",
       " 'another restaurant',\n",
       " 'another review',\n",
       " 'another reviewer',\n",
       " 'answer',\n",
       " 'answer question',\n",
       " 'ant',\n",
       " 'anticipate',\n",
       " 'antique',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyone look',\n",
       " 'anything',\n",
       " 'anything else',\n",
       " 'anything like',\n",
       " 'anything menu',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'anywhere else',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apologize',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appetite',\n",
       " 'appetizer',\n",
       " 'apple',\n",
       " 'apply',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'arcadia',\n",
       " 'area',\n",
       " 'arena',\n",
       " 'argue',\n",
       " 'arizona',\n",
       " 'arm',\n",
       " 'aroma',\n",
       " 'around',\n",
       " 'around corner',\n",
       " 'around town',\n",
       " 'arrange',\n",
       " 'arrangement',\n",
       " 'array',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'art',\n",
       " 'artichoke',\n",
       " 'artichoke dip',\n",
       " 'article',\n",
       " 'artist',\n",
       " 'arugula',\n",
       " 'as',\n",
       " 'asada',\n",
       " 'asian',\n",
       " 'asian food',\n",
       " 'asian restaurant',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'ask anything',\n",
       " 'ask could',\n",
       " 'ask manager',\n",
       " 'ask need',\n",
       " 'ask order',\n",
       " 'ask question',\n",
       " 'ask server',\n",
       " 'ask want',\n",
       " 'asparagus',\n",
       " 'aspect',\n",
       " 'ass',\n",
       " 'associate',\n",
       " 'assortment',\n",
       " 'assume',\n",
       " 'assure',\n",
       " 'asu',\n",
       " 'ate',\n",
       " 'atm',\n",
       " 'atmosphere',\n",
       " 'atmosphere friendly',\n",
       " 'atmosphere great',\n",
       " 'attach',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attendant',\n",
       " 'attention',\n",
       " 'attention detail',\n",
       " 'attentive',\n",
       " 'attitude',\n",
       " 'au',\n",
       " 'audition',\n",
       " 'authentic',\n",
       " 'authentic mexican',\n",
       " 'auto',\n",
       " 'auto body',\n",
       " 'automatically',\n",
       " 'available',\n",
       " 'ave',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'avocado',\n",
       " 'avoid',\n",
       " 'award',\n",
       " 'away',\n",
       " 'away place',\n",
       " 'awesome',\n",
       " 'awesome food',\n",
       " 'awesome great',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'az',\n",
       " 'baba',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'back another',\n",
       " 'back ask',\n",
       " 'back get',\n",
       " 'back good',\n",
       " 'back home',\n",
       " 'back next',\n",
       " 'back place',\n",
       " 'back room',\n",
       " 'back soon',\n",
       " 'back sure',\n",
       " 'back table',\n",
       " 'back time',\n",
       " 'back try',\n",
       " 'background',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'bad day',\n",
       " 'bad experience',\n",
       " 'bad food',\n",
       " 'bad meal',\n",
       " 'bad review',\n",
       " 'bad service',\n",
       " 'bad thing',\n",
       " 'bag',\n",
       " 'bagel',\n",
       " 'baguette',\n",
       " 'bake',\n",
       " 'bake potato',\n",
       " 'baked',\n",
       " 'baker',\n",
       " 'bakery',\n",
       " 'baklava',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'balsamic',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'bar area',\n",
       " 'bar food',\n",
       " 'bar go',\n",
       " 'bar great',\n",
       " 'bar restaurant',\n",
       " 'bar wait',\n",
       " 'barbecue',\n",
       " 'barber',\n",
       " 'barely',\n",
       " 'bargain',\n",
       " 'bark',\n",
       " 'barrel',\n",
       " 'barrio',\n",
       " 'barrio cafe',\n",
       " 'bartender',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basil',\n",
       " 'basis',\n",
       " 'basket',\n",
       " 'basketball',\n",
       " 'bass',\n",
       " 'bat',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batter',\n",
       " 'bay',\n",
       " 'bay area',\n",
       " 'bbq',\n",
       " 'bbq chicken',\n",
       " 'bbq sauce',\n",
       " 'beach',\n",
       " 'bean',\n",
       " 'bean rice',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'beer great',\n",
       " 'beer selection',\n",
       " 'beer tap',\n",
       " 'beer wine',\n",
       " 'beet',\n",
       " 'begin',\n",
       " 'behavior',\n",
       " 'behind',\n",
       " 'behind bar',\n",
       " 'behind counter',\n",
       " 'believe',\n",
       " 'bell',\n",
       " 'belly',\n",
       " 'belt',\n",
       " 'ben',\n",
       " 'bench',\n",
       " 'benedict',\n",
       " 'berry',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'best breakfast',\n",
       " 'best burger',\n",
       " 'best ever',\n",
       " 'best food',\n",
       " 'best mexican',\n",
       " 'best part',\n",
       " 'best pizza',\n",
       " 'best place',\n",
       " 'best restaurant',\n",
       " 'best sushi',\n",
       " 'best thing',\n",
       " 'best town',\n",
       " 'best ve',\n",
       " 'bet',\n",
       " 'beverage',\n",
       " 'beware',\n",
       " 'beyond',\n",
       " 'bf',\n",
       " 'bianco',\n",
       " 'biancoverde',\n",
       " 'big',\n",
       " 'big deal',\n",
       " 'big enough',\n",
       " 'big fan',\n",
       " 'bike',\n",
       " 'bill',\n",
       " 'biltmore',\n",
       " 'bird',\n",
       " 'birthday',\n",
       " 'birthday dinner',\n",
       " 'birthday party',\n",
       " 'biscuit',\n",
       " 'bisque',\n",
       " 'bistro',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'black',\n",
       " 'black bean',\n",
       " 'blackberry',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blanco',\n",
       " 'bland',\n",
       " 'blast',\n",
       " 'blend',\n",
       " 'bleu',\n",
       " 'bliss',\n",
       " 'block',\n",
       " 'blonde',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'bloody mary',\n",
       " 'blossom',\n",
       " 'blow',\n",
       " 'blow away',\n",
       " 'blue',\n",
       " 'blue 32',\n",
       " 'blue cheese',\n",
       " 'blue moon',\n",
       " 'blueberry',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'bob',\n",
       " 'boba',\n",
       " 'bobby',\n",
       " 'boca',\n",
       " 'body',\n",
       " 'boil',\n",
       " 'bolt',\n",
       " 'bomb',\n",
       " 'bone',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'bookstore',\n",
       " 'boot',\n",
       " 'booth',\n",
       " 'booze',\n",
       " 'border',\n",
       " 'boring',\n",
       " 'bosa',\n",
       " 'bosa donut',\n",
       " 'bother',\n",
       " 'bottle',\n",
       " 'bottle wine',\n",
       " 'bottom',\n",
       " 'bottom line',\n",
       " 'boulder',\n",
       " 'bouncer',\n",
       " 'boutique',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boxing',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'bra',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'brand new',\n",
       " 'brat',\n",
       " 'bravo',\n",
       " 'bread',\n",
       " 'bread pudding',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'breakfast burrito',\n",
       " 'breakfast lunch',\n",
       " 'breakfast place',\n",
       " 'breast',\n",
       " 'breeze',\n",
       " 'brew',\n",
       " 'brewery',\n",
       " 'brick',\n",
       " 'bride',\n",
       " 'brie',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'bring',\n",
       " 'bring back',\n",
       " 'bring cash',\n",
       " 'bring food',\n",
       " 'bring friend',\n",
       " 'brioche',\n",
       " 'brisket',\n",
       " 'brisket sandwich',\n",
       " 'brittle',\n",
       " 'broccoli',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'brow',\n",
       " 'brown',\n",
       " 'brown rice',\n",
       " 'brownie',\n",
       " 'brulee',\n",
       " 'brunch',\n",
       " 'bruschetta',\n",
       " 'btw',\n",
       " 'buca',\n",
       " 'buck',\n",
       " 'bucket',\n",
       " 'bud',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'buffalo',\n",
       " 'buffet',\n",
       " 'bug',\n",
       " 'build',\n",
       " 'building',\n",
       " 'bulb',\n",
       " 'bulk',\n",
       " 'bun',\n",
       " 'bunch',\n",
       " 'burger',\n",
       " 'burger fry',\n",
       " 'burn',\n",
       " 'burnt',\n",
       " 'burrata',\n",
       " 'burrito',\n",
       " 'burro',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butcher',\n",
       " 'butt',\n",
       " 'butter',\n",
       " 'butterfish',\n",
       " 'buttery',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buy drink',\n",
       " 'buy one',\n",
       " 'buzz',\n",
       " 'ca',\n",
       " 'ca beat',\n",
       " 'ca believe',\n",
       " 'ca even',\n",
       " 'ca find',\n",
       " 'ca get',\n",
       " 'ca go',\n",
       " 'ca help',\n",
       " 'ca really',\n",
       " 'ca remember',\n",
       " 'ca say',\n",
       " 'ca speak',\n",
       " 'ca wait',\n",
       " 'cab',\n",
       " 'cabbage',\n",
       " 'cactus',\n",
       " 'caesar',\n",
       " 'cafe',\n",
       " 'cafeteria',\n",
       " 'caffeine',\n",
       " 'cage',\n",
       " 'cajun',\n",
       " 'cake',\n",
       " 'calamari',\n",
       " 'california',\n",
       " 'call',\n",
       " 'call ahead',\n",
       " 'call back',\n",
       " 'call order',\n",
       " 'call tell',\n",
       " 'calm',\n",
       " 'calorie',\n",
       " 'calzone',\n",
       " 'camelback',\n",
       " 'camera',\n",
       " 'campus',\n",
       " 'can',\n",
       " 'cancel',\n",
       " 'candle',\n",
       " 'candy',\n",
       " 'cant',\n",
       " 'canteen',\n",
       " 'caper',\n",
       " 'cappuccino',\n",
       " 'caprese',\n",
       " 'car',\n",
       " 'car wash',\n",
       " 'caramel',\n",
       " 'caramelized',\n",
       " 'card',\n",
       " 'care',\n",
       " 'care customer',\n",
       " 'careful',\n",
       " 'carmel',\n",
       " 'carne',\n",
       " 'carne asada',\n",
       " 'carnitas',\n",
       " 'carpet',\n",
       " 'carrot',\n",
       " 'carry',\n",
       " 'cart',\n",
       " 'cartel',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cashier',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'cater',\n",
       " 'cause',\n",
       " 'cave',\n",
       " 'ceiling',\n",
       " 'celebrate',\n",
       " 'celebrate birthday',\n",
       " 'cell',\n",
       " 'cell phone',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'central',\n",
       " 'central phoenix',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'certificate',\n",
       " 'ceviche',\n",
       " 'cha',\n",
       " 'chai',\n",
       " 'chain',\n",
       " 'chain restaurant',\n",
       " 'chair',\n",
       " 'challenge',\n",
       " 'champagne',\n",
       " 'chance',\n",
       " 'chance try',\n",
       " 'chandler',\n",
       " 'chang',\n",
       " 'change',\n",
       " 'char',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charlie',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'cheap price',\n",
       " 'check',\n",
       " 'check place',\n",
       " 'cheddar',\n",
       " 'cheer',\n",
       " 'cheese',\n",
       " 'cheese burger',\n",
       " 'cheese crisp',\n",
       " 'cheese plate',\n",
       " 'cheeseburger',\n",
       " 'cheesecake',\n",
       " 'cheesesteak',\n",
       " 'cheesy',\n",
       " 'chef',\n",
       " 'chemical',\n",
       " 'cherry',\n",
       " 'chewy',\n",
       " 'chic',\n",
       " 'chicago',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'chicken breast',\n",
       " 'chicken fried',\n",
       " 'chicken salad',\n",
       " 'chicken sandwich',\n",
       " 'chicken taco',\n",
       " 'chicken tender',\n",
       " 'chicken waffle',\n",
       " 'chicken wing',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'chile',\n",
       " 'chili',\n",
       " 'chill',\n",
       " 'chilly',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'chinese food',\n",
       " 'chinese restaurant',\n",
       " 'chip',\n",
       " 'chip cookie',\n",
       " 'chip salsa',\n",
       " 'chipotle',\n",
       " 'chocolate',\n",
       " 'chocolate chip',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'chop',\n",
       " 'chop salad',\n",
       " 'chopped',\n",
       " 'chopped salad',\n",
       " 'chorizo',\n",
       " 'chris',\n",
       " 'chris bianco',\n",
       " 'christmas',\n",
       " 'christopher',\n",
       " 'chunk',\n",
       " 'church',\n",
       " 'ciao',\n",
       " 'cibo',\n",
       " 'cigar',\n",
       " 'cilantro',\n",
       " 'cinnamon',\n",
       " 'circle',\n",
       " 'city',\n",
       " 'ck',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classy',\n",
       " 'clean',\n",
       " 'clean place',\n",
       " 'clean staff',\n",
       " 'cleaning',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'clerk',\n",
       " 'client',\n",
       " 'climb',\n",
       " 'clinic',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'close home',\n",
       " 'close house',\n",
       " 'closer',\n",
       " 'closing',\n",
       " 'clothes',\n",
       " 'clothing',\n",
       " 'cloud',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'co',\n",
       " 'co worker',\n",
       " 'coal',\n",
       " 'coast',\n",
       " 'coat',\n",
       " 'cocktail',\n",
       " 'coconut',\n",
       " 'code',\n",
       " 'coe',\n",
       " 'coffee',\n",
       " 'coffee drink',\n",
       " 'coffee shop',\n",
       " 'coin',\n",
       " 'coke',\n",
       " 'cold',\n",
       " 'cole',\n",
       " 'cole slaw',\n",
       " 'coleslaw',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'color',\n",
       " 'com',\n",
       " 'combination',\n",
       " 'combine',\n",
       " 'combo',\n",
       " 'come',\n",
       " 'come across',\n",
       " 'come ask',\n",
       " 'come back',\n",
       " 'come close',\n",
       " 'come eat',\n",
       " 'come home',\n",
       " 'come little',\n",
       " 'come phoenix',\n",
       " 'come place',\n",
       " 'come right',\n",
       " 'come say',\n",
       " 'come table',\n",
       " 'come visit',\n",
       " 'comfort',\n",
       " 'comfort food',\n",
       " 'comfortable',\n",
       " 'comfy',\n",
       " 'comment',\n",
       " 'commit',\n",
       " 'common',\n",
       " 'communicate',\n",
       " 'community',\n",
       " 'comp',\n",
       " 'companion',\n",
       " 'company',\n",
       " 'comparable',\n",
       " 'compare',\n",
       " 'comparison',\n",
       " 'comped',\n",
       " 'competent',\n",
       " 'competitive',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complex',\n",
       " 'compliment',\n",
       " 'complimentary',\n",
       " 'computer',\n",
       " 'con',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concert',\n",
       " 'concoction',\n",
       " 'condiment',\n",
       " 'condition',\n",
       " 'cone',\n",
       " 'conference',\n",
       " 'confident',\n",
       " 'confirm',\n",
       " 'confuse',\n",
       " 'connection',\n",
       " 'conscious',\n",
       " 'consider',\n",
       " 'consist',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'constantly',\n",
       " 'construction',\n",
       " 'contact',\n",
       " 'contain',\n",
       " 'container',\n",
       " 'contemporary',\n",
       " 'content',\n",
       " 'continue',\n",
       " 'control',\n",
       " 'convenience',\n",
       " 'convenient',\n",
       " 'conveniently',\n",
       " 'conversation',\n",
       " 'convert',\n",
       " 'convince',\n",
       " 'cook',\n",
       " 'cook perfection',\n",
       " 'cook perfectly',\n",
       " 'cook right',\n",
       " 'cooked',\n",
       " 'cookie',\n",
       " 'cooking',\n",
       " 'cooky',\n",
       " 'cool',\n",
       " 'cooler',\n",
       " 'copy',\n",
       " 'cork',\n",
       " 'corn',\n",
       " 'cornbread',\n",
       " 'corner',\n",
       " 'cornish',\n",
       " 'cornish pasty',\n",
       " 'corporate',\n",
       " 'correct',\n",
       " 'correctly',\n",
       " 'cost',\n",
       " 'costco',\n",
       " 'costume',\n",
       " 'cotton',\n",
       " 'couch',\n",
       " 'could',\n",
       " 'could ask',\n",
       " 'could believe',\n",
       " 'could easily',\n",
       " 'could eat',\n",
       " 'could even',\n",
       " 'could find',\n",
       " 'could get',\n",
       " 'could give',\n",
       " 'could go',\n",
       " 'could good',\n",
       " 'could hear',\n",
       " 'could make',\n",
       " 'could say',\n",
       " 'could see',\n",
       " 'could take',\n",
       " 'could tell',\n",
       " 'could wait',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'countless',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'couple hour',\n",
       " 'couple time',\n",
       " 'couple week',\n",
       " 'couple year',\n",
       " 'coupon',\n",
       " 'course',\n",
       " 'court',\n",
       " 'courteous',\n",
       " 'cousin',\n",
       " 'cover',\n",
       " 'cow',\n",
       " 'cowboy',\n",
       " 'cowboy ciao',\n",
       " 'coworker',\n",
       " 'coworkers',\n",
       " 'cozy',\n",
       " 'crab',\n",
       " 'crab cake',\n",
       " 'crack',\n",
       " 'cracker',\n",
       " 'craft',\n",
       " 'crap',\n",
       " 'crappy',\n",
       " 'crave',\n",
       " 'craving',\n",
       " 'crazy',\n",
       " 'cream',\n",
       " 'cream cheese',\n",
       " 'cream sauce',\n",
       " 'creamy',\n",
       " 'create',\n",
       " 'creation',\n",
       " 'creative',\n",
       " 'creativity',\n",
       " 'credit',\n",
       " ...]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary\n",
    "words = pipe['vectorizer'].get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "77cb3926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe['clf'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c741f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of times each word appears across all 1 star doc\n",
    "bad_word_count = pipe['clf'].feature_count_[0,:]\n",
    "good_word_count = pipe['clf'].feature_count_[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ef9235aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>73.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zinburger</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zucchini</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            bad   good\n",
       "word                  \n",
       "00         32.0   32.0\n",
       "000         4.0    8.0\n",
       "07          2.0    5.0\n",
       "10         73.0  129.0\n",
       "10 15       2.0    6.0\n",
       "...         ...    ...\n",
       "zero       13.0    6.0\n",
       "zinburger   0.0    9.0\n",
       "zone        1.0    6.0\n",
       "zoo         0.0    7.0\n",
       "zucchini    1.0   10.0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df = pd.DataFrame({'word':words,\n",
    "                        'bad':bad_word_count,\n",
    "                         'good':good_word_count}).set_index('word')\n",
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ae1aa9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 1 to the columns\n",
    "words_df = words_df + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4ba57f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>74.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 15</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zinburger</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zucchini</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            bad   good\n",
       "word                  \n",
       "00         33.0   33.0\n",
       "000         5.0    9.0\n",
       "07          3.0    6.0\n",
       "10         74.0  130.0\n",
       "10 15       3.0    7.0\n",
       "...         ...    ...\n",
       "zero       14.0    7.0\n",
       "zinburger   1.0   10.0\n",
       "zone        2.0    7.0\n",
       "zoo         1.0    8.0\n",
       "zucchini    2.0   11.0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "36aaea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert counts into frequencies\n",
    "words_df.bad = words_df.bad/words_df.bad.sum()\n",
    "words_df.good = words_df.good/words_df.good.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3dc60e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratios\n",
    "words_df['bad_ratio'] = words_df.bad/words_df.good\n",
    "words_df['good_ratio'] = words_df.good/words_df.bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "57e1c67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>bad_ratio</th>\n",
       "      <th>good_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fantastic</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.030478</td>\n",
       "      <td>32.810409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.050755</td>\n",
       "      <td>19.702329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yum</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.055514</td>\n",
       "      <td>18.013558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outstanding</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.063444</td>\n",
       "      <td>15.761863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mozzarella</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.072297</td>\n",
       "      <td>13.831839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pasty</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.075824</td>\n",
       "      <td>13.188498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamb</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.075824</td>\n",
       "      <td>13.188498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gem</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.077719</td>\n",
       "      <td>12.866827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>favorite</th>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.079508</td>\n",
       "      <td>12.577324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bianco</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.079712</td>\n",
       "      <td>12.545157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love place</th>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.081275</td>\n",
       "      <td>12.303904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dentist</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.081810</td>\n",
       "      <td>12.223486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pastry</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.084021</td>\n",
       "      <td>11.901815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>organic</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.086355</td>\n",
       "      <td>11.580145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesa</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.088822</td>\n",
       "      <td>11.258474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yummy</th>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.089676</td>\n",
       "      <td>11.151250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one favorite</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.090109</td>\n",
       "      <td>11.097639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delish</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.091434</td>\n",
       "      <td>10.936803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>die</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.091434</td>\n",
       "      <td>10.936803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affordable</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.091434</td>\n",
       "      <td>10.936803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bad      good  bad_ratio  good_ratio\n",
       "word                                                   \n",
       "fantastic     0.000040  0.001303   0.030478   32.810409\n",
       "perfect       0.000079  0.001565   0.050755   19.702329\n",
       "yum           0.000020  0.000358   0.055514   18.013558\n",
       "outstanding   0.000020  0.000313   0.063444   15.761863\n",
       "mozzarella    0.000020  0.000275   0.072297   13.831839\n",
       "pasty         0.000020  0.000262   0.075824   13.188498\n",
       "lamb          0.000020  0.000262   0.075824   13.188498\n",
       "gem           0.000020  0.000256   0.077719   12.866827\n",
       "favorite      0.000199  0.002498   0.079508   12.577324\n",
       "bianco        0.000020  0.000249   0.079712   12.545157\n",
       "love place    0.000079  0.000978   0.081275   12.303904\n",
       "dentist       0.000020  0.000243   0.081810   12.223486\n",
       "pastry        0.000020  0.000236   0.084021   11.901815\n",
       "organic       0.000020  0.000230   0.086355   11.580145\n",
       "mesa          0.000020  0.000224   0.088822   11.258474\n",
       "yummy         0.000060  0.000664   0.089676   11.151250\n",
       "one favorite  0.000040  0.000441   0.090109   11.097639\n",
       "delish        0.000020  0.000217   0.091434   10.936803\n",
       "die           0.000040  0.000434   0.091434   10.936803\n",
       "affordable    0.000020  0.000217   0.091434   10.936803"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.sort_values(by='good_ratio', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "933bde6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Disclaimer: Like many of you, I am a sucker fo...</td>\n",
       "      <td>5</td>\n",
       "      <td>disclaimer like many sucker charm little home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>I'm from Chicago so I'm picky with my pizza--t...</td>\n",
       "      <td>5</td>\n",
       "      <td>'m chicago 'm picky pizza -- place right ny st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>On one of my many visits to see mi amore, he t...</td>\n",
       "      <td>5</td>\n",
       "      <td>one many visit see mi amore take fantastic lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>WOW this place is good!  SO good!  And not jus...</td>\n",
       "      <td>5</td>\n",
       "      <td>wow place good good yummy good intrinsically g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>I love this place! I love that it's to-go only...</td>\n",
       "      <td>5</td>\n",
       "      <td>love place love 's to-go 3 hour wait like pizz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>The new Harkins Cine Capri, one of the first t...</td>\n",
       "      <td>5</td>\n",
       "      <td>new harkins cine capri one first thing open te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>I have been to this place many times and the f...</td>\n",
       "      <td>5</td>\n",
       "      <td>place many time food service always great exci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>Honestly, this is the best pizza that I've had...</td>\n",
       "      <td>5</td>\n",
       "      <td>honestly best pizza 've arizona 'm sucker wood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>Great product! I was on a mission to make home...</td>\n",
       "      <td>5</td>\n",
       "      <td>great product mission make homemade mozzarella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>Delicious food, amazing martini's, and wonderf...</td>\n",
       "      <td>5</td>\n",
       "      <td>delicious food amaze martini 's wonderful dess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>Stopped by here for lunch today... I saw the B...</td>\n",
       "      <td>5</td>\n",
       "      <td>stop lunch today ... saw burger sign outside t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>The mozzarella tomato and basil sandwich is th...</td>\n",
       "      <td>5</td>\n",
       "      <td>mozzarella tomato basil sandwich best sandwich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>Yup. It's all true. Great food, super charming...</td>\n",
       "      <td>5</td>\n",
       "      <td>yup 's true great food super charm place intim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>Once we went to Grimaldi's in Hoboken, NJ and ...</td>\n",
       "      <td>5</td>\n",
       "      <td>go grimaldi 's hoboken nj n't impress yet firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>I found this place via Google while in town fo...</td>\n",
       "      <td>5</td>\n",
       "      <td>find place via google town business 's tuck aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>Pizzeria Bianco: Before and After \\nCited as \"...</td>\n",
       "      <td>5</td>\n",
       "      <td>pizzeria bianco cite `` best pizza america '' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>Sauce is my kind of place.  Great, inexpensive...</td>\n",
       "      <td>5</td>\n",
       "      <td>sauce kind place great inexpensive food casual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>Wow... i don't think I've ever been in a more ...</td>\n",
       "      <td>5</td>\n",
       "      <td>wow ... n't think 've ever narrow place .. eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>Owner Daniel M. is one of my most favorite res...</td>\n",
       "      <td>5</td>\n",
       "      <td>owner daniel m. one favorite restaurateur phoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>This place was great. When one of my coworkers...</td>\n",
       "      <td>5</td>\n",
       "      <td>place great one coworkers send email group vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>We love 5th and Wine and recommend it to anyon...</td>\n",
       "      <td>5</td>\n",
       "      <td>love 5th wine recommend anyone ask appetizer w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>Really great food and service, and it worked o...</td>\n",
       "      <td>5</td>\n",
       "      <td>really great food service work fine two kid ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6022</th>\n",
       "      <td>::Sigh::\\n\\nI love places like this.  It is ad...</td>\n",
       "      <td>5</td>\n",
       "      <td>:sigh love place like adorable unique intimate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166</th>\n",
       "      <td>You don't expect to find a good restaurant in ...</td>\n",
       "      <td>5</td>\n",
       "      <td>n't expect find good restaurant strip mall nex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6915</th>\n",
       "      <td>Why would I go to a restaurant and hope for th...</td>\n",
       "      <td>5</td>\n",
       "      <td>would go restaurant hope bad 'm snob snob conv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7150</th>\n",
       "      <td>I love everything at Market bistro, but I espe...</td>\n",
       "      <td>5</td>\n",
       "      <td>love everything market bistro especially love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7206</th>\n",
       "      <td>One of the best dining experiences we had in P...</td>\n",
       "      <td>5</td>\n",
       "      <td>one best dining experience phoenix surprise wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7219</th>\n",
       "      <td>5 stars? Definitely!\\n\\nUpon walking in, every...</td>\n",
       "      <td>5</td>\n",
       "      <td>5 star definitely upon walk everything atmosph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7354</th>\n",
       "      <td>When a man falls in love, it's a special thing...</td>\n",
       "      <td>5</td>\n",
       "      <td>man fall love 's special thing calloused hand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>With a few hours past and a few tasks accompli...</td>\n",
       "      <td>5</td>\n",
       "      <td>hour past task accomplish next stop day would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813</th>\n",
       "      <td>This is by far the best farmer's market I've b...</td>\n",
       "      <td>5</td>\n",
       "      <td>far best farmer 's market 've valley still sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8130</th>\n",
       "      <td>This place is as good as I'd heard.  We came h...</td>\n",
       "      <td>5</td>\n",
       "      <td>place good 'd hear come day-late birthday dinn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8208</th>\n",
       "      <td>Decided on a whim at the last minute to go her...</td>\n",
       "      <td>5</td>\n",
       "      <td>decide whim last minute go dinner tonight gues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9106</th>\n",
       "      <td>Picazzo's Organic Italian Kitchen is a gem in ...</td>\n",
       "      <td>5</td>\n",
       "      <td>picazzo 's organic italian kitchen gem many pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9201</th>\n",
       "      <td>My husband took me here on a Friday night ...a...</td>\n",
       "      <td>5</td>\n",
       "      <td>husband take friday night ... hear good thing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9389</th>\n",
       "      <td>I really like this place... \\nTaking the advic...</td>\n",
       "      <td>5</td>\n",
       "      <td>really like place ... take advice yelp stop wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551</th>\n",
       "      <td>I love this store.  The produce is always fres...</td>\n",
       "      <td>5</td>\n",
       "      <td>love store produce always fresh interesting se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9793</th>\n",
       "      <td>I am a vegetarian and there is a ton of great ...</td>\n",
       "      <td>5</td>\n",
       "      <td>vegetarian ton great stuff pita jungle hummus ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  stars  \\\n",
       "30    Disclaimer: Like many of you, I am a sucker fo...      5   \n",
       "138   I'm from Chicago so I'm picky with my pizza--t...      5   \n",
       "205   On one of my many visits to see mi amore, he t...      5   \n",
       "452   WOW this place is good!  SO good!  And not jus...      5   \n",
       "816   I love this place! I love that it's to-go only...      5   \n",
       "913   The new Harkins Cine Capri, one of the first t...      5   \n",
       "1189  I have been to this place many times and the f...      5   \n",
       "1222  Honestly, this is the best pizza that I've had...      5   \n",
       "1611  Great product! I was on a mission to make home...      5   \n",
       "1650  Delicious food, amazing martini's, and wonderf...      5   \n",
       "1916  Stopped by here for lunch today... I saw the B...      5   \n",
       "2058  The mozzarella tomato and basil sandwich is th...      5   \n",
       "2105  Yup. It's all true. Great food, super charming...      5   \n",
       "2177  Once we went to Grimaldi's in Hoboken, NJ and ...      5   \n",
       "2221  I found this place via Google while in town fo...      5   \n",
       "2311  Pizzeria Bianco: Before and After \\nCited as \"...      5   \n",
       "2683  Sauce is my kind of place.  Great, inexpensive...      5   \n",
       "3016  Wow... i don't think I've ever been in a more ...      5   \n",
       "3623  Owner Daniel M. is one of my most favorite res...      5   \n",
       "5210  This place was great. When one of my coworkers...      5   \n",
       "5398  We love 5th and Wine and recommend it to anyon...      5   \n",
       "5768  Really great food and service, and it worked o...      5   \n",
       "6022  ::Sigh::\\n\\nI love places like this.  It is ad...      5   \n",
       "6166  You don't expect to find a good restaurant in ...      5   \n",
       "6915  Why would I go to a restaurant and hope for th...      5   \n",
       "7150  I love everything at Market bistro, but I espe...      5   \n",
       "7206  One of the best dining experiences we had in P...      5   \n",
       "7219  5 stars? Definitely!\\n\\nUpon walking in, every...      5   \n",
       "7354  When a man falls in love, it's a special thing...      5   \n",
       "7575  With a few hours past and a few tasks accompli...      5   \n",
       "7813  This is by far the best farmer's market I've b...      5   \n",
       "8130  This place is as good as I'd heard.  We came h...      5   \n",
       "8208  Decided on a whim at the last minute to go her...      5   \n",
       "9106  Picazzo's Organic Italian Kitchen is a gem in ...      5   \n",
       "9201  My husband took me here on a Friday night ...a...      5   \n",
       "9389  I really like this place... \\nTaking the advic...      5   \n",
       "9551  I love this store.  The produce is always fres...      5   \n",
       "9793  I am a vegetarian and there is a ton of great ...      5   \n",
       "\n",
       "                                         processed_text  \n",
       "30    disclaimer like many sucker charm little home ...  \n",
       "138   'm chicago 'm picky pizza -- place right ny st...  \n",
       "205   one many visit see mi amore take fantastic lit...  \n",
       "452   wow place good good yummy good intrinsically g...  \n",
       "816   love place love 's to-go 3 hour wait like pizz...  \n",
       "913   new harkins cine capri one first thing open te...  \n",
       "1189  place many time food service always great exci...  \n",
       "1222  honestly best pizza 've arizona 'm sucker wood...  \n",
       "1611  great product mission make homemade mozzarella...  \n",
       "1650  delicious food amaze martini 's wonderful dess...  \n",
       "1916  stop lunch today ... saw burger sign outside t...  \n",
       "2058  mozzarella tomato basil sandwich best sandwich...  \n",
       "2105  yup 's true great food super charm place intim...  \n",
       "2177  go grimaldi 's hoboken nj n't impress yet firs...  \n",
       "2221  find place via google town business 's tuck aw...  \n",
       "2311  pizzeria bianco cite `` best pizza america '' ...  \n",
       "2683  sauce kind place great inexpensive food casual...  \n",
       "3016  wow ... n't think 've ever narrow place .. eve...  \n",
       "3623  owner daniel m. one favorite restaurateur phoe...  \n",
       "5210  place great one coworkers send email group vis...  \n",
       "5398  love 5th wine recommend anyone ask appetizer w...  \n",
       "5768  really great food service work fine two kid ag...  \n",
       "6022  :sigh love place like adorable unique intimate...  \n",
       "6166  n't expect find good restaurant strip mall nex...  \n",
       "6915  would go restaurant hope bad 'm snob snob conv...  \n",
       "7150  love everything market bistro especially love ...  \n",
       "7206  one best dining experience phoenix surprise wi...  \n",
       "7219  5 star definitely upon walk everything atmosph...  \n",
       "7354  man fall love 's special thing calloused hand ...  \n",
       "7575  hour past task accomplish next stop day would ...  \n",
       "7813  far best farmer 's market 've valley still sma...  \n",
       "8130  place good 'd hear come day-late birthday dinn...  \n",
       "8208  decide whim last minute go dinner tonight gues...  \n",
       "9106  picazzo 's organic italian kitchen gem many pi...  \n",
       "9201  husband take friday night ... hear good thing ...  \n",
       "9389  really like place ... take advice yelp stop wa...  \n",
       "9551  love store produce always fresh interesting se...  \n",
       "9793  vegetarian ton great stuff pita jungle hummus ...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find some text with 'mozzerella'\n",
    "yelp.loc[yelp.processed_text.str.contains('mozzarella')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20655e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
